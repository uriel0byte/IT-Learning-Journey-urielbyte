# Day 3: Splunk Basics - Did you SIEM?

## üìã Quick Facts
- **Date Completed:** December 3, 2025
- **Time Spent:** 3 hours
- **Difficulty:** ‚òÖ‚òÖ‚òÖ‚òÜ (Hard)
- **Category:** SIEM / Log Analysis / Defensive Security
- **Room URL:** https://tryhackme.com/room/splunkforloganalysis-aoc2025-x8fj2k4rqp

---

## üéØ Challenge Overview

This challenge introduced SIEM (Security Information and Event Management) operations using Splunk, the industry-leading log analysis platform. The scenario involved investigating a ransomware attack by King Malhare's Bandit Bunnies on The Best Festival Company (TBFC) systems. A ransom message appeared on the SOC dashboard demanding TBFC turn Christmas into "EAST-mas." With McSkidy missing and the network under attack, I used Splunk to analyze web traffic and firewall logs, tracing the complete attack chain from initial reconnaissance through SQL injection exploitation to ransomware deployment and C2 communication.

**Learning Objectives:**
- Ingest and interpret custom log data in Splunk
- Create and apply custom field extractions
- Use Search Processing Language (SPL) to filter and refine search results
- Conduct a real investigation to uncover key insights
- Correlate logs across multiple data sources

---

## üí° What I Learned

### Splunk SIEM Platform Fundamentals

**What is Splunk:**
Splunk is an industry-leading SIEM platform that ingests, indexes, and analyzes massive volumes of machine data (logs, metrics, events) to enable security monitoring, threat detection, and incident investigation.

**This was my FIRST time using Splunk** and working with SPL (Search Processing Language).

**Key Splunk Interface Components:**

**1. Search & Reporting App**
- Primary interface for security analysts
- Where all log queries and investigations happen
- Access via left panel: "Search & Reporting"

**2. Search Query Bar**
- Where SPL queries are written
- Time range selector (All time, Last 24 hours, custom)
- Search button to execute queries

**3. Timeline Visualization**
- Histogram showing event distribution over time
- Identifies traffic spikes (potential attack windows)
- Visual representation of 17,172+ events

**4. Fields Panel (Left Side)**
- **Selected fields**: Currently displayed in event summary
- **Interesting fields**: Automatically extracted or manually added fields
- Fields with `#` prefix: Auto-generated by Splunk (like `#date_hour`)

**5. Event Details**
- Shows parsed details of individual log entries
- Displays extracted fields: `user_agent`, `path`, `status`, `client_ip`
- Click to expand and see full event context

**6. Visualization Tab**
- Converts query results into charts/graphs
- Alternative to "Events" tab for visual analysis

### Data Sources in This Investigation

Two pre-ingested datasets:

**1. web_traffic (sourcetype=web_traffic)**
- Contains events related to web connections to/from web server
- Fields: `client_ip`, `user_agent`, `path`, `status`, `_time`
- Shows HTTP requests, responses, and connection patterns

**2. firewall_logs (sourcetype=firewall_logs)**
- Contains firewall traffic logs (allowed/blocked)
- Fields: `src_ip`, `dest_ip`, `action`, `protocol`, `dest_port`, `reason`, `bytes_transferred`
- Local IP assigned to web server: **10.10.1.5**

### Initial Triage and Exploration

**Step 1: View All Logs**

```spl
index=main
```

**What this does:**
- Queries all data in the `main` index
- Shows both `web_traffic` and `firewall_logs`
- Returns 17,172 events total
- Set time range to "All time"

**Step 2: Focus on Web Traffic**

```spl
index=main sourcetype=web_traffic
```

**What this shows:**
- Only web server connection logs
- Filters out firewall logs
- Reveals HTTP activity patterns

**Key Components of Search Results:**

**Timeline:**
- Shows distribution of 17,172 events over time
- Distinctive **traffic spike** visible (attack window)
- Normal daily log volume vs. abnormal spike

**Selected Fields:**
- `host` - Log source system
- `source` - Original log file path
- `sourcetype` - Custom type (web_traffic)

**Interesting Fields:**
- `user_agent` - Browser/tool identification
- `path` - URI being requested
- `client_ip` - Source IP address
- `status` - HTTP response codes

### Visualizing the Attack Timeline

**Objective:** Identify which day received abnormal traffic volume.

**SPL Query:**
```spl
index=main sourcetype=web_traffic | timechart span=1d count
```

**Breaking down the query:**
- `index=main sourcetype=web_traffic` - Get web traffic logs
- `|` - Pipe operator (sends results to next command)
- `timechart span=1d count` - Chart event count per day

**Results:**
- Shows daily event counts
- Visual graph reveals traffic spike on specific day
- Clear period of intense activity = attack phase

**Visualization Tab:**
- Click "Visualization" for graphical representation
- Easier to spot anomalies visually

**Reverse Sort for Better Analysis:**

```spl
index=main sourcetype=web_traffic | timechart span=1d count | sort by count | reverse
```

**What this adds:**
- `sort by count` - Order by event count
- `reverse` - Descending order (highest first)
- Shows peak attack day at top of results

**Finding:** Clear period of intense activity identified = King Malhare's main attack phase.

### Anomaly Detection (Finding Suspicious Values)

**Strategy:** Examine key fields for suspicious values.

**Field 1: user_agent Analysis**

Click on `user_agent` field in left panel to see all user agent values.

**Normal user agents:**
- Mozilla/5.0 (Firefox)
- Chrome variants
- Safari variants
- Legitimate web browsers

**Suspicious user agents discovered:**
- `curl` - Command-line HTTP tool
- `wget` - File download utility
- `sqlmap` - SQL injection tool
- `zgrab` - Network scanner
- `Havij` - Automated SQL injection tool

**Why suspicious:** Attackers use scripts/tools, not browsers. These user agents indicate automated attack tools.

**Field 2: client_ip Analysis**

Click on `client_ip` field to see source IP addresses.

**Finding:** One particular IP address stands out with extremely high request count compared to others.

**Field 3: path Analysis**

Click on `path` field to see URIs being requested.

**Suspicious paths discovered:**
- `/.env` - Configuration file exposure attempts
- `/.git*` - Version control directory probing
- `*phpinfo*` - PHP info page reconnaissance
- `../../etc/passwd` - Path traversal attacks
- `*redirect*` - Open redirect testing
- `/backup.zip` - Sensitive file download
- `/logs.tar.gz` - Log exfiltration
- `/shell.php?cmd=*` - Webshell execution
- `/bunnylock.bin` - Ransomware binary

### Filtering Out Benign Traffic

**Problem:** King Malhare's bunnies use scripts/tools, not standard browsers.

**Solution:** Exclude legitimate user agents to focus on attacks.

**SPL Query:**
```spl
index=main sourcetype=web_traffic user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari* user_agent!=*Firefox*
```

**Breaking down the filters:**
- `user_agent!=*Mozilla*` - Exclude Mozilla-based browsers
- `user_agent!=*Chrome*` - Exclude Chrome
- `user_agent!=*Safari*` - Exclude Safari
- `user_agent!=*Firefox*` - Exclude Firefox
- `!=` operator means "does not contain"
- `*` is wildcard (matches any characters)

**Result:** Only suspicious user agents remain (curl, wget, sqlmap, zgrab).

**Next Step:** Click on `client_ip` field to see which IP is responsible.

**Finding:** A single IP address responsible for ALL suspicious user agents!

**Note this IP down** - replace `<REDACTED>` in upcoming queries with this IP.

### Narrowing Down Suspicious IPs

**Real-World Scenario:** Multiple IPs constantly attempt attacks.

**Goal:** Identify top attacking IPs using non-browser tools.

**SPL Query:**
```spl
sourcetype=web_traffic user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari* user_agent!=*Firefox* | stats count by client_ip | sort -count | head 5
```

**Breaking down the query:**
- First part: Filter out benign user agents (same as before)
- `| stats count by client_ip` - Count events per IP address
- `| sort -count` - Sort in descending order (- means reverse)
- `| head 5` - Show top 5 IPs

**Alternative to reverse:**
- `sort -count` achieves same result as `sort count | reverse`
- `-` prefix is shorthand for descending order

**Result:** Confirms top IP used by Bandit Bunnies.

---

## Complete Attack Chain Investigation (Step-by-Step)

### Phase 1: Reconnaissance (Footprinting)

**Goal:** Identify initial probing for exposed configuration files.

**SPL Query:**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND path IN ("/.env", "/*phpinfo*", "/.git*") | table _time, path, user_agent, status
```

**Breaking down the query:**
- `client_ip="<REDACTED>"` - Focus on attacker IP
- `AND` - Boolean operator (both conditions must be true)
- `path IN ("/.env", "/*phpinfo*", "/.git*")` - Match multiple paths
- `| table _time, path, user_agent, status` - Display specific columns

**Results Found:**
- Attacker used low-level tools: `curl`, `wget`
- Targeted sensitive files:
  - `/.env` - Environment configuration
  - `/phpinfo.php` - PHP configuration page
  - `/.git/config` - Git version control
- Received error codes: **404** (Not Found), **403** (Forbidden), **401** (Unauthorized)

**What this means:** Attacker probing for common misconfigurations. Failed attempts indicate files are properly secured or don't exist.

### Phase 2: Enumeration (Vulnerability Testing)

**Goal:** Search for path traversal and open redirect vulnerabilities.

**SPL Query (Initial):**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND path="*..*" OR path="*redirect*"
```

**What attacker is testing:**
- **Path traversal:** `../../etc/passwd`, `../../windows/system32/`
- **Open redirects:** URLs with `redirect` parameter

**Refined Query for Counts:**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND path="*..\/..\/*" OR path="*redirect*" | stats count by path
```

**Why the change:**
- `*..\/..\\/*` - Escaped characters for path traversal patterns
- `| stats count by path` - Count how many times each path was attempted

**Results:**
- Multiple attempts to read system files (`../../*`)
- Attacker moved beyond simple scanning
- Active vulnerability testing underway

**Significance:** This is **enumeration**‚Äîattacker is actively testing for exploitable vulnerabilities, not just passively gathering info.

### Phase 3: Exploitation (SQL Injection Attack)

**Goal:** Find automated attack tools and SQL injection payloads.

**SPL Query:**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND user_agent IN ("*sqlmap*", "*Havij*") | table _time, path, status
```

**Breaking down the query:**
- `user_agent IN ("*sqlmap*", "*Havij*")` - Look for known SQL injection tools
- **sqlmap:** Most popular automated SQL injection tool
- **Havij:** Another automated SQL injection tool

**Results Found:**
- Confirmed use of SQL injection tools
- Attack strings visible: `SLEEP(5)` payloads
- HTTP **504 Gateway Timeout** status codes

**What HTTP 504 means:**
- Server took too long to respond
- Often confirms **time-based SQL injection** success
- `SLEEP(5)` makes database pause 5 seconds
- If server times out, SQL injection worked!

**Attack Technique:** Time-based blind SQL injection
- Attacker can't see database output directly
- Uses time delays to infer database responses
- `SLEEP(5)` = if query succeeds, database sleeps 5 seconds

### Phase 4: Data Exfiltration

**Goal:** Identify attempts to download large sensitive files.

**SPL Query:**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND path IN ("*backup.zip*", "*logs.tar.gz*") | table _time path, user_agent
```

**What attacker is downloading:**
- **backup.zip** - Database/website backups
- **logs.tar.gz** - Compressed log files (may contain credentials, session tokens)

**Tools used:**
- `curl` - Command-line file transfer
- `zgrab` - Network scanner with download capability

**Why this matters:**
- Attacker exfiltrating large chunks of data
- Compressed archives contain sensitive information
- Double-extortion preparation (ransomware + data theft)

**Next step:** Confirm these connections in firewall logs.

### Phase 5: Ransomware Staging & Remote Code Execution (RCE)

**Goal:** Identify webshell upload and ransomware execution.

**SPL Query:**
```spl
sourcetype=web_traffic client_ip="<REDACTED>" AND path IN ("*bunnylock.bin*", "*shell.php?cmd=*") | table _time, path, user_agent, status
```

**Critical discoveries:**
- `/shell.php?cmd=` - **Webshell** uploaded and executed
- `/shell.php?cmd=./bunnylock.bin` - Ransomware binary executed via webshell
- **bunnylock.bin** - Ransomware payload

**What is a webshell:**
- Malicious script (PHP, JSP, ASP) uploaded to web server
- Provides remote command execution interface
- Attacker can run ANY command via `?cmd=` parameter

**Attack progression:**
1. SQL injection ‚Üí gain database access
2. Upload webshell via SQL injection
3. Execute commands through webshell
4. Run ransomware binary

**This is RCE (Remote Code Execution):**
- Attacker has full control over web server
- Can execute arbitrary commands
- Game over for server security

### Phase 6: Correlate Outbound C2 Communication

**Goal:** Prove server established connection to attacker's Command & Control server.

**Pivot to Firewall Logs:**
Now switching from `web_traffic` to `firewall_logs` source type.

**SPL Query:**
```spl
sourcetype=firewall_logs src_ip="10.10.1.5" AND dest_ip="<REDACTED>" AND action="ALLOWED" | table _time, action, protocol, src_ip, dest_ip, dest_port, reason
```

**Breaking down the query:**
- `sourcetype=firewall_logs` - Switch to firewall data
- `src_ip="10.10.1.5"` - Compromised web server IP
- `dest_ip="<REDACTED>"` - Attacker's IP
- `action="ALLOWED"` - Connection was permitted
- Display key fields: time, action, protocol, IPs, port, reason

**Results:**
- **ACTION=ALLOWED** - Firewall allowed connection
- **REASON=C2_CONTACT** - Explicitly labeled as Command & Control
- Outbound connection from server to attacker IP
- Suspicious destination port

**What this proves:**
- Server immediately established connection to attacker
- Ransomware reporting back to C2
- Malware communication channel active
- Attacker can send commands to compromised server

**Why C2 matters:**
- Ransomware communicates with attacker's server
- Sends encryption keys, system info, ransom demands
- Receives commands from attacker
- Enables remote control

### Phase 7: Calculate Volume of Data Exfiltrated

**Goal:** Quantify how much data was stolen.

**SPL Query:**
```spl
sourcetype=firewall_logs src_ip="10.10.1.5" AND dest_ip="<REDACTED>" AND action="ALLOWED" | stats sum(bytes_transferred) by src_ip
```

**New SPL function:**
- `stats sum(bytes_transferred)` - Calculate total bytes
- `sum()` - Aggregation function (adds up all values)
- `by src_ip` - Group results by source IP

**Results:**
- **Huge volume** of data transferred from web server to C2
- Measured in bytes (convert to MB/GB for readability)
- Confirms data exfiltration occurred

**Why this matters:**
- Quantifies damage (how much data stolen)
- Evidence for incident report
- Helps assess breach severity
- Supports double-extortion scenario (ransomware + data theft)

---

## Complete Investigation Summary

**Identity Found:**
Attacker identified via highest volume of malicious web traffic from single external IP address.

**Intrusion Vector:**
Attack followed clear progression in web logs (`sourcetype=web_traffic`):

**1. Reconnaissance:**
- Probes via cURL/Wget
- Looking for configuration files (`/.env`)
- Testing path traversal vulnerabilities

**2. Exploitation:**
- SQLmap user agents detected
- Specific payloads: `SLEEP(5)`
- HTTP 504 status codes = successful time-based SQL injection

**3. Payload Delivery:**
- Webshell upload: `shell.php`
- Ransomware execution: `cmd=./bunnylock.bin`
- RCE achieved

**4. C2 Confirmation:**
- Pivot to firewall logs (`sourcetype=firewall_logs`)
- Compromised server (SRC_IP: 10.10.1.5)
- Outbound C2 connection to attacker IP
- ACTION=ALLOWED, REASON=C2_CONTACT

**5. Data Exfiltration:**
- Large volume of bytes transferred
- Backup files and logs stolen
- Double-extortion confirmed

---

## üõ†Ô∏è Tools & Techniques Used

### Tools
1. **Splunk Enterprise** - SIEM platform for log ingestion and analysis
2. **SPL (Search Processing Language)** - Query language for Splunk
3. **Timeline Visualization** - Graph events to identify attack windows
4. **Field Extraction** - Parse log data into structured fields
5. **Correlation Engine** - Link events across multiple data sources

### Techniques
- **Log correlation** - Pivoting between `web_traffic` and `firewall_logs`
- **Anomaly detection** - Identifying traffic spikes and suspicious user agents
- **Attack chain reconstruction** - Tracing attacker progression chronologically
- **Threat hunting** - Filtering benign traffic to focus on malicious activity
- **Data aggregation** - Calculating totals (`sum`), grouping by fields (`stats`)
- **Timeline analysis** - Identifying peak attack periods with `timechart`
- **Boolean logic** - Using `AND`, `OR`, `IN` operators
- **Wildcard matching** - Using `*` for pattern matching
- **Field filtering** - Excluding benign values with `!=`

---

## ü§î Challenges I Faced

**SPL Syntax Learning Curve:** This was my first time using any SIEM query language. I struggled with SPL syntax for about **1 hour**, trying to remember the correct operators (`!=`, `AND`, `OR`, `IN`) and function syntax (`stats`, `timechart`, `sort`).

**What Made SPL Hard:**
- **Pipe operator (`|`)** - Understanding how to chain commands
- **Boolean operators** - When to use `AND` vs. `OR`
- **Wildcard syntax** - `*Mozilla*` vs. `Mozilla*` vs. `*Mozilla`
- **Function syntax** - `stats sum()`, `timechart span=1d`, `sort -count`
- **Field names** - Remembering exact field names (`client_ip` vs. `src_ip`)

**Remembering vs. Understanding:** I initially tried to memorize SPL commands, but then I realized this was my first exposure‚ÄîI needed to focus on understanding the logic, not memorization. I reminded myself this is a skill I'll develop over time through the roadmap I've planned for SIEM training.

**Log Correlation Challenge:**
Understanding how to **pivot between data sources** was conceptually difficult:
- Start with `web_traffic` to identify attacker activity
- Find attacker IP and compromised server IP
- Switch to `firewall_logs` using those IPs
- Prove C2 communication happened

**Why pivoting is hard:**
- Different field names in different sources (`client_ip` vs. `src_ip`)
- Understanding which data source has which information
- Knowing when to switch sources

**Filtering Noise:** Real-world logs contain massive amounts of benign traffic. Learning to filter out legitimate user agents (Mozilla, Chrome, Safari, Firefox) to focus on suspicious activity was critical for efficient analysis.

**Initial overwhelm:**
- 17,172 events seemed like too much to analyze
- Didn't know where to start
- Timeline visualization helped identify attack window

**Time Investment:**
This challenge took **3 hours** because:
- First exposure to Splunk interface
- Learning SPL from scratch
- Understanding log correlation concepts
- Tracing complete attack chain
- Answering detailed investigation questions

**What helped:**
- Following systematic investigation methodology
- Starting broad (all logs) ‚Üí narrowing down (specific IP)
- Using visualizations to spot anomalies
- Taking notes on SPL syntax for reference

---

## ‚úÖ How This Helps My Career

SIEM expertise appears in **78% of SOC Analyst job postings**, making it the **#1 technical requirement**. This challenge gave me hands-on experience with real-world SOC analyst workflows.

**Why SIEM Skills Are Critical:**

**Industry Statistics:**
- **78% of SOC job postings** require SIEM experience
- **Splunk is the #1 SIEM platform** in enterprise environments
- **Average SOC analyst salary:** $75,000-$95,000 (SIEM proficiency adds $10-15k)
- **Daily SOC work:** 60-70% is log analysis and alert triage

**Real SOC Analyst Workflows I Practiced:**

**Alert Triage:**
- Starting with high-volume alerts
- Filtering noise (benign traffic)
- Identifying true positives vs. false positives
- Prioritizing based on severity

**Threat Hunting:**
- Proactively searching for indicators of compromise (IOCs)
- Looking for suspicious user agents (sqlmap, curl, wget)
- Identifying unusual IP addresses
- Detecting anomalous traffic patterns

**Incident Investigation:**
- Reconstructing attack timelines chronologically
- Tracing attacker progression through kill chain
- Correlating evidence across multiple data sources
- Quantifying damage (bytes exfiltrated)

**Log Correlation:**
- Connecting dots between web traffic and firewall logs
- Pivoting between data sources intelligently
- Understanding which logs contain which information
- Building complete attack narrative

**Splunk/SPL Proficiency:**

**Technical Skills Gained:**
- **SPL query writing** - Essential for daily SOC operations
- **Field extraction** - Understanding log structure
- **Data visualization** - Timeline analysis, traffic spike detection
- **Boolean logic** - Combining multiple conditions
- **Aggregation functions** - Counting, summing, grouping
- **Pattern matching** - Wildcards and regular expressions

**Platform Knowledge:**
- Navigating Splunk interface
- Understanding indexes and sourcetypes
- Using field panel for quick analysis
- Switching between Events and Visualization tabs
- Time range selection for focused investigations

**Attack Pattern Recognition:**

**Understanding Attacker TTPs (Tactics, Techniques, Procedures):**
- **Reconnaissance:** Config file probing, directory enumeration
- **Exploitation:** SQL injection, path traversal
- **Post-Exploitation:** Webshell upload, RCE
- **Command & Control:** Outbound C2 connections
- **Data Exfiltration:** Large file downloads
- **Impact:** Ransomware deployment

**Recognizing Attack Chains:**
- Recon ‚Üí Exploitation ‚Üí Exfiltration ‚Üí Ransomware
- Understanding attack progression
- Identifying which phase attacker is in
- Predicting next likely attacker action

**Real-World Applications:**

**Example 1 - Daily SOC Monitoring:**
Alert fires for unusual traffic ‚Üí Query Splunk ‚Üí Filter benign traffic ‚Üí Identify suspicious IP ‚Üí Trace activity ‚Üí Escalate to incident response

**Example 2 - Threat Hunting:**
Hypothesis: "Are there any SQL injection attempts in our environment?" ‚Üí Write SPL query for SQL injection indicators ‚Üí Find attempts ‚Üí Investigate source IPs ‚Üí Check if exploitation successful

**Example 3 - Incident Response:**
Server compromised ‚Üí Search all logs for that server IP ‚Üí Identify initial access vector ‚Üí Trace lateral movement ‚Üí Calculate data exfiltration ‚Üí Build incident timeline

**Career Skills Developed:**
- ‚úÖ **SIEM proficiency** - Splunk (industry-standard)
- ‚úÖ **SPL mastery** - Writing effective queries
- ‚úÖ **Log analysis** - Finding needles in haystacks
- ‚úÖ **Threat detection** - Identifying attack patterns
- ‚úÖ **Incident investigation** - Reconstructing attack timelines
- ‚úÖ **Data correlation** - Connecting evidence across sources
- ‚úÖ **Critical thinking** - Understanding attacker mindset
- ‚úÖ **Technical documentation** - Recording findings clearly

**Interview Talking Point:** "I have hands-on experience conducting SIEM investigations using Splunk, where I analyzed web traffic and firewall logs to reconstruct a complete ransomware attack chain‚Äîfrom initial reconnaissance through SQL injection exploitation, webshell deployment, RCE, C2 communication, and data exfiltration. I can write complex SPL queries using boolean operators, aggregation functions, and wildcards to hunt for threats. I understand how to correlate logs across multiple sources, identify attack patterns in large datasets, filter benign traffic to focus on true threats, and reconstruct attack timelines chronologically. I've practiced the complete SOC analyst workflow: alert triage, threat hunting, incident investigation, and quantifying breach impact. This directly applies to daily SOC operations monitoring security alerts and investigating incidents in production environments."

---

## üîó Security+ Connection

**Domain 4.0 - Security Operations (28%):** SIEM usage, log analysis, monitoring, threat detection, incident investigation, alert triage, security information and event management.

**Domain 2.0 - Threats, Vulnerabilities & Mitigations (22%):** Attack techniques (SQL injection, webshells, ransomware, path traversal), reconnaissance methods, exploitation tactics, C2 communication.

**Domain 3.0 - Security Architecture (18%):** Log aggregation, security monitoring architecture, data correlation.

---

## üì∏ Evidence

**üîî REMINDER:** Go back to this room and take 2-3 screenshots:
1. Timeline visualization showing traffic spike
2. SPL query filtering attacker IP
3. C2 communication in firewall logs

**Note:** Screenshots were not captured during initial completion. Documentation based on hands-on completion and room content review.

### Key Findings:
- Successfully identified attacker IP via suspicious user agent filtering
- Traced complete attack chain across 6 phases using SPL queries
- Used `timechart` to visualize traffic spike indicating main attack window
- Correlated web traffic and firewall logs to prove C2 communication
- Calculated total bytes exfiltrated using `stats sum(bytes_transferred)`
- Confirmed ransomware execution via webshell RCE

---

## üìö Key Takeaways for Future Reference

### Essential SPL (Search Processing Language) Syntax

**Basic Query Structure:**
```spl
index=<index_name> sourcetype=<source_type> <field>=<value>
```

**Common Search Operators:**
```spl
# Basic filtering
index=main sourcetype=web_traffic

# Boolean operators
AND  # Both conditions must be true
OR   # Either condition must be true
NOT  # Exclude matching events

# Comparison operators
=    # Equals (exact match)
!=   # Not equals (exclude)
>    # Greater than
<    # Less than

# Wildcard matching
*    # Match any characters
?    # Match single character

# Examples:
user_agent=*sqlmap*           # Contains "sqlmap"
user_agent!=*Mozilla*         # Does NOT contain "Mozilla"
status>=400                   # Status code 400 or higher
```

**IN Operator (Match Multiple Values):**
```spl
path IN ("/.env", "/.git*", "/*phpinfo*")
# Matches ANY of the specified values
```

**Pipe Operator (Chaining Commands):**
```spl
index=main | <command1> | <command2> | <command3>
# Results flow left to right through pipe
```

### Critical SPL Commands for SOC Analysts

**1. timechart - Visualize Events Over Time**
```spl
index=main | timechart span=1d count
# span=1d   ‚Üí Group by 1 day
# span=1h   ‚Üí Group by 1 hour
# span=15m  ‚Üí Group by 15 minutes
# count     ‚Üí Count events per time bucket
```

**2. stats - Aggregate and Calculate**
```spl
# Count events by field
| stats count by client_ip

# Calculate sum
| stats sum(bytes_transferred) by src_ip

# Multiple calculations
| stats count, avg(response_time), max(bytes) by host

# Other functions: min(), avg(), median(), stdev(), values(), dc()
```

**3. table - Display Specific Fields**
```spl
| table _time, client_ip, path, status
# Shows only specified columns
# _time is always useful (timestamp)
```

**4. sort - Order Results**
```spl
| sort by count              # Ascending order
| sort -count               # Descending order (- prefix)
| sort by count | reverse   # Alternative to -count
```

**5. head/tail - Limit Results**
```spl
| head 10   # Show first 10 results
| tail 20   # Show last 20 results
```

**6. reverse - Reverse Order**
```spl
| reverse   # Flip result order
```

### Complete Investigation Workflow (Template)

**Phase 1: Initial Exploration**
```spl
# View all data
index=main

# Focus on specific source
index=main sourcetype=web_traffic

# Identify time range of interest
index=main sourcetype=web_traffic | timechart span=1h count
```

**Phase 2: Anomaly Detection**
```spl
# Examine suspicious fields
index=main sourcetype=web_traffic 
| stats count by user_agent | sort -count

# Look for suspicious IPs
index=main sourcetype=web_traffic 
| stats count by client_ip | sort -count | head 10
```

**Phase 3: Filter Benign Traffic**
```spl
# Exclude legitimate browsers
index=main sourcetype=web_traffic 
user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari*
```

**Phase 4: Focus on Attacker IP**
```spl
# Investigate specific IP
sourcetype=web_traffic client_ip="<ATTACKER_IP>"
| table _time, path, user_agent, status
```

**Phase 5: Trace Attack Stages**
```spl
# Reconnaissance
client_ip="<IP>" AND path IN ("/.env", "/.git*")

# Exploitation
client_ip="<IP>" AND user_agent IN ("*sqlmap*", "*Havij*")

# Exfiltration
client_ip="<IP>" AND path IN ("*backup.zip*", "*logs.tar.gz*")

# RCE
client_ip="<IP>" AND path="*shell.php?cmd=*"
```

**Phase 6: Correlate with Other Sources**
```spl
# Pivot to firewall logs
sourcetype=firewall_logs src_ip="<COMPROMISED_SERVER>" 
AND dest_ip="<ATTACKER_IP>"
| table _time, action, protocol, dest_port, reason
```

**Phase 7: Quantify Impact**
```spl
# Calculate data exfiltrated
sourcetype=firewall_logs src_ip="<SERVER>" dest_ip="<ATTACKER>"
| stats sum(bytes_transferred) by dest_ip
```

### Field Name Conventions (Important!)

**Web Traffic Logs:**
- `client_ip` - Source IP making request
- `user_agent` - Browser/tool identification
- `path` - URI being requested
- `status` - HTTP response code
- `_time` - Timestamp

**Firewall Logs:**
- `src_ip` - Source IP (who initiated connection)
- `dest_ip` - Destination IP (where connection goes)
- `action` - ALLOWED or BLOCKED
- `protocol` - TCP, UDP, ICMP
- `dest_port` - Destination port number
- `bytes_transferred` - Data volume
- `reason` - Why action taken (e.g., C2_CONTACT)

**‚ö†Ô∏è CRITICAL:** Field names differ between sources!
- Web traffic uses `client_ip`
- Firewall logs use `src_ip`
- Know which fields exist in which data source

### Common HTTP Status Codes (Quick Reference)

**Success:**
- **200** - OK (request succeeded)

**Client Errors:**
- **401** - Unauthorized (authentication required)
- **403** - Forbidden (no permission)
- **404** - Not Found (resource doesn't exist)

**Server Errors:**
- **500** - Internal Server Error
- **502** - Bad Gateway
- **503** - Service Unavailable
- **504** - Gateway Timeout (often indicates SQL injection success!)

### Suspicious User Agents (Threat Hunting List)

**SQL Injection Tools:**
- `sqlmap` - Most popular automated SQL injection
- `Havij` - Automated SQL injection
- `jSQL Injection` - Another injection tool

**Web Scanners:**
- `nikto` - Web vulnerability scanner
- `dirb` - Directory brute-forcer
- `gobuster` - Directory/file enumeration
- `wfuzz` - Web fuzzer

**Command-Line Tools (often suspicious):**
- `curl` - File transfer
- `wget` - File download
- `python-requests` - Scripting
- `Go-http-client` - Go language HTTP library

**Network Scanners:**
- `zgrab` - Network scanner
- `masscan` - Port scanner
- `nmap` - Port scanner

**‚ö†Ô∏è Context matters:** `curl` and `wget` aren't always malicious, but non-browser user agents deserve investigation.

### Attack Chain Patterns (Recognition Guide)

**Typical Attack Progression:**

**1. Reconnaissance (Footprinting):**
- Probing for `/.env`, `/.git`, `/phpinfo.php`
- Directory enumeration
- User agents: `curl`, `wget`, `dirb`
- HTTP errors: 404, 403, 401

**2. Enumeration (Vulnerability Testing):**
- Path traversal: `../../etc/passwd`
- Open redirect testing
- Parameter fuzzing
- More active than reconnaissance

**3. Exploitation:**
- SQL injection: `sqlmap`, `SLEEP(5)` payloads
- RCE attempts
- File upload vulnerabilities
- HTTP 504 timeouts (SQL injection success)

**4. Post-Exploitation:**
- Webshell upload: `shell.php`, `cmd.php`
- Command execution: `?cmd=whoami`
- Privilege escalation attempts

**5. Data Exfiltration:**
- Large file downloads: `backup.zip`, `logs.tar.gz`
- Database dumps
- Credential harvesting

**6. Persistence/Impact:**
- Ransomware deployment: `bunnylock.bin`
- C2 communication establishment
- Lateral movement attempts

### Filtering Best Practices

**Start Broad, Narrow Down:**
```spl
# Step 1: All web traffic
index=main sourcetype=web_traffic

# Step 2: Exclude benign
user_agent!=*Mozilla* user_agent!=*Chrome*

# Step 3: Focus on suspicious IP
client_ip="<ATTACKER_IP>"

# Step 4: Specific attack phase
AND path="*shell.php?cmd=*"
```

**Use Visualizations:**
- Timeline charts reveal traffic spikes
- Bar charts show top IPs/user agents
- Statistics highlight anomalies

**Leverage Field Panel:**
- Click fields to see value distribution
- Quickly identify outliers
- No query writing needed for basic exploration

### Log Correlation Strategies

**When to Pivot Between Sources:**

**Scenario 1: Found suspicious IP in web logs**
‚Üí Pivot to firewall logs to see where that IP connected

**Scenario 2: Found compromised server in firewall logs**
‚Üí Pivot to web logs to see how it was compromised

**Scenario 3: Found malware indicator in endpoint logs**
‚Üí Pivot to network logs to see C2 communication

**Keys to Successful Correlation:**
1. Know your field names (differ between sources)
2. Identify common fields (IPs, timestamps)
3. Build timeline across sources
4. Confirm findings with multiple data sources

### Time Range Selection Strategy

**Initial Investigation:**
- Use "All time" to see full picture
- Identify traffic spike period

**Focused Investigation:**
- Narrow to attack window (e.g., specific day)
- Reduces noise, speeds up queries

**Timeline Building:**
- Use `timechart` to visualize by hour/day
- Identify exactly when attack phases occurred

### SPL Query Optimization Tips

**Faster Queries:**
- Filter early (put field filters before pipe)
- Use specific time ranges
- Avoid wildcards at start of strings (`*malicious` slower than `malicious*`)

**Better Results:**
- Use `table` to see only relevant fields
- Use `head` to limit results
- Use `stats` to aggregate instead of showing raw events

**Debugging:**
- Remove pipe commands one at a time to isolate issues
- Test filters individually
- Check field names (case-sensitive!)

### Real-World SOC Applications

**Daily Alert Triage:**
1. Query alerts from SIEM
2. Filter false positives (known benign traffic)
3. Identify suspicious patterns
4. Escalate true positives

**Threat Hunting:**
1. Develop hypothesis ("Are there SQL injection attempts?")
2. Write SPL query to test hypothesis
3. Investigate findings
4. Document patterns

**Incident Response:**
1. Identify compromised asset
2. Query all logs for that asset
3. Build attack timeline
4. Quantify impact (data loss, systems affected)
5. Provide evidence for remediation

**Compliance Reporting:**
1. Query specific timeframes
2. Aggregate statistics
3. Generate visualizations
4. Export for auditors

### Common Mistakes to Avoid

**‚ùå Forgetting wildcards:**
```spl
user_agent=sqlmap        # Only matches exact "sqlmap"
user_agent=*sqlmap*      # ‚úÖ Matches "sqlmap/1.0", "sqlmap-dev"
```

**‚ùå Wrong boolean operators:**
```spl
client_ip="1.2.3.4" OR path="*.php"   # Either condition
client_ip="1.2.3.4" AND path="*.php"  # Both conditions
```

**‚ùå Mixing field names:**
```spl
# web_traffic uses client_ip
# firewall_logs uses src_ip
# Don't mix them!
```

**‚ùå Not using pipes correctly:**
```spl
index=main stats count        # ‚ùå Wrong
index=main | stats count      # ‚úÖ Correct
```

**‚ùå Case sensitivity:**
```spl
# Field names are case-sensitive
client_IP      # ‚ùå Wrong
client_ip      # ‚úÖ Correct
```

### Quick Reference Card (Print This!)

**Most Used SPL Commands:**
```spl
index=main sourcetype=<type>                    # Basic search
| stats count by <field>                        # Count by field
| stats sum(<field>) by <other_field>           # Calculate sum
| timechart span=1d count                       # Timeline
| table _time, <field1>, <field2>               # Display fields
| sort -count                                   # Sort descending
| head 10                                       # First 10 results
| reverse                                       # Reverse order
<field>=<value>                                 # Exact match
<field>!=<value>                                # Not equals
<field>=*<value>*                               # Contains
<field> IN ("val1", "val2")                     # Multiple values
AND / OR / NOT                                  # Boolean logic
```

**Investigation Checklist:**
- [ ] Identify data sources available
- [ ] Query all data, observe patterns
- [ ] Use timeline to find attack window
- [ ] Examine suspicious fields (user_agent, client_ip, path)
- [ ] Filter benign traffic
- [ ] Focus on specific attacker
- [ ] Trace attack phases chronologically
- [ ] Correlate across multiple sources
- [ ] Quantify impact
- [ ] Document findings

---
